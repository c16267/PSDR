% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fn_psdr.R
\name{psdr}
\alias{psdr}
\title{A unified Principal sufficient dimension reduction method}
\usage{
psdr(
  x,
  y,
  init = NULL,
  H = NULL,
  lambda = NULL,
  h = NULL,
  delta = NULL,
  eps = 1e-05,
  max.iter = NULL,
  loss = NULL,
  a = NULL,
  c = NULL,
  stochastic = FALSE
)
}
\arguments{
\item{x}{data matrix}

\item{y}{either continuous or (+1,-1) typed binary response vector}

\item{init}{initial parameter theta}

\item{H}{the number of slicing. default value is 10}

\item{lambda}{hyperparameter for the loss function. default value is 0.1}

\item{h}{very small interval for calculating numerical derivatives for a given arbitrary loss function}

\item{delta}{learning rate. default value is 0.1}

\item{eps}{threshold for stopping iteration with respect to the magnitude of derivative, default value is 1.0e-5}

\item{max.iter}{maximum iteration number for the optimization process. default value is 30}

\item{loss}{pre-specified loss functions are "logistic", svm","l2svm","lwpsvm", and user-defined loss function object also can be used formed by inside double quotation mark}

\item{a}{hyperparameter for LUM type loss function}

\item{c}{hyperparameter for LUM type loss function}

\item{stochastic}{user's can implement batch stochastic gradient descent method in case of large number of observations. default is set to FALSE.}
}
\value{
An estimated matrix B for a sufficient dimension reduction will be returned
}
\description{
Principal Sufficient Dimension Reduction method
}
\examples{
\donttest{
set.seed(1234)
n <- 300; p <- 5; H <- 10; lambda <- 0.1; eps <- 1.0e-5;
max.iter <- 10; h <- 1.0e-5; delta <- 3*1.0e-1;
init <- rnorm(sd=1,n=p)
x <- matrix(rnorm(n*p, 0, 1), n, p)
err <- rnorm(n, 0, .2)
B <- matrix(0, p, 2)
B[1,1] <- 1; B[2,2] <- 1
x1 <- x \%*\% B[,1]
x2 <- x \%*\% B[,2]
fx <-  x1/(0.5 + (x2 + 1)^2)
y <- fx + err
y.binary <- sign(fx + err)
my.logistic <- function(m,...){
rslt <- log(1+exp(-m))
return(rslt)
}
psdr(x, y)
psdr(x, y, init, H,lambda, h, delta, eps, max.iter, loss="svm")
psdr(x, y, init, H,lambda, h, delta, eps, max.iter, loss="LUM", a=1, c=10^8)
psdr(x, y.binary, init, H, lambda=0.5, h, delta, eps, max.iter, loss="my.logistic")

#wisconsin breast cancer data example
data(wisc)
x.wisc <- matrix(unlist(wisc[,-c(1,2)]), ncol = 30)
y.wisc <- y.wisc.binary <- 2*as.numeric(as.factor(unlist(wisc[,2]))) - 3
n <- length(y.wisc.binary) #n=569
p <- ncol(x.wisc)  #p=30
init <- rnorm(sd=1,n=p)
wisc.obj <- psdr(x.wisc, y.wisc.binary, init, H=20,lambda=0.1, h=1.0e-6, delta=0.5,
                          eps=10^-4, max.iter=30, loss="wlogistic")
value.lsvm <- wisc.obj$values
lsvm <- round(wisc.obj$vectors,3)
x.lsvm <- x.wisc \%*\% lsvm
plot(x.lsvm[,1], x.lsvm[,2], type = "n", xlab = "1st predictor", ylab  = "2nd predictor")
points(x.lsvm[y.wisc.binary == 1,1], x.lsvm[y.wisc.binary == 1,2], col = 4, pch = "+")
points(x.lsvm[y.wisc.binary != 1,1], x.lsvm[y.wisc.binary != 1,2], col = 2)

#Boston housing data example
data("BostonHousing")
attach(BostonHousing)
BostonHousing <- BostonHousing[BostonHousing$crim < 3.2 , -c(4,9)]
X <- BostonHousing[,-12]
Y <- BostonHousing[,"medv"]
p <- ncol(X);H <- 20; lambda <- 0.1; eps <- 1.0e-5;
max.iter <- 100; h <- 1.0e-5; delta <- 2*1.0e-1;
init <- rnorm(sd=1,n=p)
rslt <- psdr(X, Y, init, H,lambda, h, delta, eps, max.iter, loss="svm")
value.lsvm <- rslt$values
lsvm <- round(rslt$vectors,3)
X <- as.matrix(X); x.lsvm <- X \%*\% lsvm
plot(Y, x.lsvm[,1], type = "p", ylab = "1st predictor", xlab="medv", cex=.7);
lines(lowess(Y, x.lsvm[,1]), col="red", lwd=1)
legend(38, 2.0, legend=c("lowess(cor:-0.86)"),col=c("red"), lty=1:1, cex=0.7)
plot(Y, x.lsvm[,2], type = "p", ylab = "2nd predictor", xlab="medv", cex=.7);
lines(lowess(Y, x.lsvm[,2]), col="blue", lwd=1)
legend(38, 7.8, legend=c("lowess(cor: 0.86)"),col=c("blue"), lty=1:1, cex=0.7)
}
}
\seealso{
\code{\link{plot.psdr}} \code{\link{dimension}}
}
\author{
Jungmin Shin, \email{jungminshin@korea.ac.kr}, Seung Jun Shin, \email{sjshin@korea.ac.kr}
}
