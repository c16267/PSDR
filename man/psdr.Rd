% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fn_psdr.R
\name{psdr}
\alias{psdr}
\title{Unified Principal sufficient dimension reduction methods}
\usage{
psdr(
  x,
  y,
  init = NULL,
  H = NULL,
  lambda = NULL,
  delta = NULL,
  h = 1e-05,
  eps = 1e-05,
  max.iter = NULL,
  loss = NULL,
  a = NULL,
  c = NULL,
  stochastic = FALSE,
  plot = FALSE
)
}
\arguments{
\item{x}{data matrix}

\item{y}{either continuous or (+1,-1) typed binary response vector}

\item{init}{initial coefficient vector. If not specified, random vector from standard normal distribution is applied by default}

\item{H}{the number of slices. default value is 10}

\item{lambda}{hyperparameter for the loss function. default value is 0.1}

\item{delta}{learning rate for gradient descent method. default value is 0.1}

\item{h}{very small interval for calculating numerical derivatives for a given arbitrary loss function, default is 1.0e-5}

\item{eps}{threshold for stopping iteration with respect to the magnitude of derivative, default value is 1.0e-5}

\item{max.iter}{maximum iteration number for the optimization process. default value is 30}

\item{loss}{pre-specified loss functions are "logistic", svm","l2svm","lwpsvm", and user-defined loss function object also can be used formed by inside double quotation mark}

\item{a}{the first hyperparameter for the LUM loss function}

\item{c}{second hyperparameter for the LUM loss function}

\item{stochastic}{specify whether the user want to use the stochastic gradient descent algorithm. default is FALSE}

\item{plot}{visualize user defined loss function. default is FALSE}
}
\value{
An estimated basis for central subspace and its eigenvalues and eigenvectors for SDR is returned
}
\description{
Principal Sufficient Dimension Reduction methods
}
\examples{
\donttest{
set.seed(1)
n <- 200;
p <- 5;
H <- 10;
lambda <- 0.1
eps <- 1.0e-5
max.iter <- 10
init.theta <- rnorm(p,0,1)
h <- 1.0e-6; delta <- 5*1.0e-1
x <- matrix(rnorm(n*p, 0, 2), n, p)
err <- rnorm(n, 0, .2)
B <- matrix(0, p, 2)
B[1,1] <- 1; B[2,2] <- 1
x1 <- x \%*\% B[,1]
x2 <- x \%*\% B[,2]
fx <-  x1/(0.5 + (x2 + 1)^2)
y <- c(fx + err) # response
my.hinge <- function(m,...){
 rslt <- (1-m)*(as.numeric((1-m) > 0))
 return(rslt)
}
obj <- psdr(x, y, init.theta, H,lambda, h, delta, eps, max.iter, loss="svm")
psdr(x, y, init.theta, H,lambda, h, delta, eps, max.iter, loss="my.hinge")
print(obj)
plot(obj)


##real data: Boston housing data
data("BostonHousing")
attach(BostonHousing)
BostonHousing <- BostonHousing[BostonHousing$crim < 3.2 , -c(4,9)]
X <- BostonHousing[,-12]
Y <- BostonHousing[,"medv"]
p <- ncol(X); H <- 20; lambda <- 0.1; eps <- 1.0e-5;
max.iter <- 100; h <- 1.0e-5; delta <- 2*1.0e-1;
init.theta <- rnorm(sd=1,n=p)
rslt <- psdr(X, Y, init.theta, H,lambda, h, delta, eps, max.iter, loss="svm")
value.lsvm <- rslt$values
lsvm <- round(rslt$vectors,3)
X <- as.matrix(X)
x.lsvm <- X \%*\% lsvm
plot(x.lsvm[,1],Y , type = "p", xlab = expression(hat(b)[1]^T*X), ylab="medv", cex=1)
lines(lowess( x.lsvm[,1], Y), col="red", lwd=2)
plot(x.lsvm[,2], Y, type = "p", xlab = expression(hat(b)[2]^T*X), ylab="medv", cex=1);
lines(lowess(x.lsvm[,2], Y), col="blue", lwd=2)

##real data: Wisconsin diagnostic breast cancer data
data(wisc)
x.wisc <- matrix(unlist(wisc[,-c(1,2)]), ncol = 30)
y.wisc <- 2*as.numeric(as.factor(unlist(wisc[,2]))) - 3
init.theta <- rnorm(dim(x.wisc)[2],0,1)
wisc.obj <- psdr(x.wisc, y.wisc, init.theta, H=20,lambda=0.1, h=1.0e-6,
                delta=0.5,eps=10^-4, max.iter=30, loss="wlogistic")
value.lsvm <- wisc.obj$values
lsvm <- round(wisc.obj$vectors,3)
x.lsvm <- x.wisc \%*\% lsvm
par(mar=c(5,5,5,5), oma=c(1,1,1,1))
plot(x.lsvm[,1], x.lsvm[,2], type = "n", xlab = "1st predictor", ylab  = "2nd predictor")
points(x.lsvm[y.wisc == 1,1], x.lsvm[y.wisc == 1,2], col = 4, pch = "+")
points(x.lsvm[y.wisc != 1,1], x.lsvm[y.wisc != 1,2], col = 2)
}
}
\seealso{
\code{plot.psdr}
}
\author{
Jungmin Shin, \email{jungminshin@korea.ac.kr}, Seung Jun Shin, \email{sjshin@korea.ac.kr}
}
